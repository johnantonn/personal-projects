{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdu84I27EyWSGZThtdJmM/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnantonn/deep-learning-practice/blob/main/tensor_ops.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tensor Operations\n",
        "This notebook contains the definition of tensors along with a number of tensor operations in numpy.\n",
        "\n",
        "All transformations learned by neural networkscan be reduced to a handful of tensor operations that are applied to tensors of numeric data:\n",
        "- Element-wise operations\n",
        "- Broadcasting\n",
        "- Tensor product\n",
        "- Tensor reshaping\n",
        "\n",
        "Finally, there is a block of code providing a geometric interpretation of tensor operations. "
      ],
      "metadata": {
        "id": "0edETJUAjCo4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "metadata": {
        "id": "NWPeCKIYjAbs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensors\n",
        "\n",
        "A tensor is a container for numerical data.\n",
        "\n",
        "Tensors are defined by three key attributes:\n",
        "- Number of axes (rank) or `ndim`: the number of dimensions\n",
        "- Shape: tuple of integers that describes how many dimensions there are along each axis.\n",
        "- Data type (or `dtype`): the type of data contained in the tensor e.g. `float32`, `float64` etc."
      ],
      "metadata": {
        "id": "bgvkGzLmkmHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# rank-0 tensor (scalar)\n",
        "tensor_r0 = np.array(10)\n",
        "print(\"Rank:\", tensor_r0.ndim)\n",
        "print(\"Shape:\", tensor_r0.shape)\n",
        "print(\"- - - - - - - - - - - -\")\n",
        "\n",
        "# rank-1 tensor\n",
        "tensor_r1 = np.array([1, 2, 3, 4, 5])\n",
        "print(\"Rank:\", tensor_r1.ndim)\n",
        "print(\"Shape:\", tensor_r1.shape)\n",
        "print(\"- - - - - - - - - - - -\")\n",
        "\n",
        "\n",
        "# rank-2 tensor\n",
        "tensor_r2 = np.array([[1, 2, 3, 4, 5], [1, 2, 3, 4, 5]])\n",
        "print(\"Rank:\", tensor_r2.ndim)\n",
        "print(\"Shape:\", tensor_r2.shape)\n",
        "print(\"- - - - - - - - - - - -\")\n",
        "\n",
        "# rank-3 tensor\n",
        "tensor_r3 = np.array([[[1,2,3,4,5], [1,2,3,4,5]]])\n",
        "print(\"Rank:\", tensor_r3.ndim)\n",
        "print(\"Shape:\", tensor_r3.shape)\n",
        "print(\"- - - - - - - - - - - -\")\n",
        "\n",
        " # MNIST dataset example\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "print(\"Rank:\", x_train.ndim)\n",
        "print(\"Shape:\", x_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3xzjkXvjGGC",
        "outputId": "ed083be3-3bdb-42ad-ff41-4e712f2bb046"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Rank: 0\n",
            "Shape: ()\n",
            "- - - - - - - - - - - -\n",
            "Rank: 1\n",
            "Shape: (5,)\n",
            "- - - - - - - - - - - -\n",
            "Rank: 2\n",
            "Shape: (2, 5)\n",
            "- - - - - - - - - - - -\n",
            "Rank: 3\n",
            "Shape: (1, 2, 5)\n",
            "- - - - - - - - - - - -\n",
            "Rank: 3\n",
            "Shape: (60000, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Element-wise operations\n",
        "\n",
        "In this code block naive implementations of `relu` and `add` are provided and compared against the vectorized `numpy` implementations."
      ],
      "metadata": {
        "id": "48oFr9oKmo-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# naive ReLU\n",
        "def naive_relu(x):\n",
        "  assert len(x.shape) == 2\n",
        "  x = x.copy()\n",
        "  for i in range(x.shape[0]):\n",
        "    for j in range(x.shape[1]):\n",
        "      x[i, j] = max(x[i, j], 0)\n",
        "  return x\n",
        "\n",
        "# naive add\n",
        "def naive_add(x, y):\n",
        "  assert len(x.shape) == 2\n",
        "  assert x.shape == y.shape\n",
        "  x = x.copy()\n",
        "  for i in range(x.shape[0]):\n",
        "    for j in range(x.shape[1]):\n",
        "      x[i, j] += y[i, j]\n",
        "  return x\n",
        "\n",
        "# toy data\n",
        "x = np.random.random((20, 100))\n",
        "y = np.random.random((20, 100))\n",
        "\n",
        "# naive implementations\n",
        "t0 = time.time()\n",
        "for _ in range(1000):\n",
        "  z = naive_add(x, y)\n",
        "  z = naive_relu(z)\n",
        "print(\"Naive took: {0:.2f} s\".format(time.time() - t0))\n",
        "\n",
        "# numpy vectorized implementations\n",
        "t1 = time.time()\n",
        "for _ in range(1000):\n",
        "  z = x + y\n",
        "  z = np.maximum(z, 0)\n",
        "print(\"Vectorized took: {0:.2f} s\".format(time.time() - t1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vyNGguvljGD4",
        "outputId": "20d1ea6d-17f1-40fc-d6e3-9306b58fe31c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive took: 2.29 s\n",
            "Vectorized took: 0.01 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Broadcasting\n",
        "\n",
        "Broadcasting facilitates numerical operations between tensors of different shapes."
      ],
      "metadata": {
        "id": "YXLFp01Uo42D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# toy data\n",
        "x = np.random.random((40, 10))\n",
        "y = np.random.random((10,))\n",
        "\n",
        "# broadcasting intuition\n",
        "Y = np.expand_dims(y, axis=0) # expand the dimensions of y\n",
        "Y = np.concatenate([y] * 40, axis=0) # repeat y 40 times along axis=0\n",
        "print(\"Shape of x:\", x.shape)\n",
        "print(\"Shape of Y:\", Y.shape)\n",
        "\n",
        "# naive implementation of adding a matrix (rank-2 tensor) and a vector (rank-1 tensor)\n",
        "def naive_add_matrix_and_vector(x, y):\n",
        "  assert len(x.shape) == 2\n",
        "  assert len(y.shape) == 1\n",
        "  assert x.shape[1] == y.shape[0]\n",
        "  x = x.copy()\n",
        "  for i in range(x.shape[0]):\n",
        "    for j in range(x.shape[1]):\n",
        "      x[i, j] += y[j]\n",
        "  return x\n",
        "\n",
        "# example\n",
        "print(\"Shape of (x+y):\", naive_add_matrix_and_vector(x, y).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uA8Z3LbPjGBK",
        "outputId": "a834cc56-f0ee-4c9d-d75b-965f882e118f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x: (40, 10)\n",
            "Shape of Y: (400,)\n",
            "Shape of (x+y): (40, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor product \n",
        "\n",
        "The *tensor product* or *dot product* (not to be confused with the element-wise product) is one of the most common and useful tensor operations. In numpy, a tensor product is done using the `np.dot` function."
      ],
      "metadata": {
        "id": "yeT4wAJd6ygO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vector-vector dot product\n",
        "def naive_vector_dot(x, y):\n",
        "  assert len(x.shape) == 1\n",
        "  assert len(y.shape) == 1\n",
        "  assert x.shape[0] == y.shape[0]\n",
        "  z = 0.\n",
        "  for i in range(x.shape[0]):\n",
        "    z += x[i] * y[i]\n",
        "  return z\n",
        "\n",
        "# toy data\n",
        "x = np.random.random((10,))\n",
        "y = np.random.random((10,))\n",
        "\n",
        "# z is a scalar\n",
        "z = naive_vector_dot(x, y)\n",
        "print(z)\n",
        "print(\"- - - - - - - - - \")\n",
        "\n",
        "# matrix-vector dot product\n",
        "def naive_matrix_vector_dot(x, y):\n",
        "  z = np.zeros(x.shape[0])\n",
        "  for i in range(x.shape[0]):\n",
        "    z[i] = naive_vector_dot(x[i, :], y)\n",
        "  return z\n",
        "\n",
        "# toy data\n",
        "x = np.random.random((5, 10))\n",
        "y = np.random.random((10,))\n",
        "\n",
        "# z is a vector\n",
        "z = naive_matrix_vector_dot(x, y)\n",
        "print(z)\n",
        "print(\"- - - - - - - - - \")\n",
        "\n",
        "\n",
        "# matrix-matrix dot product\n",
        "def naive_matrix_dot(x, y):\n",
        "  assert len(x.shape) == 2\n",
        "  assert len(y.shape) == 2\n",
        "  assert x.shape[1] == y.shape[0]\n",
        "  z = np.zeros((x.shape[0], y.shape[1]))\n",
        "  for i in range(x.shape[0]):\n",
        "    for j in range(y.shape[1]):\n",
        "      row_x = x[i, :]\n",
        "      col_y = y[:, j]\n",
        "      z[i, j] = naive_vector_dot(row_x, col_y)\n",
        "  return z\n",
        "\n",
        "# toy data\n",
        "x = np.random.random((4, 10))\n",
        "y = np.random.random((10, 2))\n",
        "\n",
        "# z is a 4x2 matrix\n",
        "z = naive_matrix_dot(x, y)\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_tjAq3w-jFvw",
        "outputId": "0629ff10-e3df-49bb-e257-ed73393749e1"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.167749553552792\n",
            "- - - - - - - - - \n",
            "[4.68566983 4.21193009 2.80086741 3.01636514 1.84756883]\n",
            "- - - - - - - - - \n",
            "[[1.94669792 1.36877593]\n",
            " [2.78408974 2.9120038 ]\n",
            " [2.71824168 2.65759662]\n",
            " [2.31653082 2.37440425]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tensor reshaping\n",
        "\n",
        "This type of operation is usually applied for preprocessing purposes, i.e. when there's a need to change to rearrange the dimensions/values of an existing tensor."
      ],
      "metadata": {
        "id": "n9mxjyByKGB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# toy data matrix of shape 3x2\n",
        "x = np.array([[0., 1.],\n",
        "              [2., 3.],\n",
        "              [4., 5.]])\n",
        "print(\"Shape of x:\", x.shape)\n",
        "print(x)\n",
        "print(\"- - - - - \")\n",
        "\n",
        "# reshape to 2x3\n",
        "x = x.reshape((2, 3))\n",
        "print(\"Shape of x after reshape:\", x.shape)\n",
        "print(x)\n",
        "print(\"- - - - - \")\n",
        "\n",
        "# reshape to 6x1\n",
        "x = x.reshape((6, 1))\n",
        "print(\"Shape of x after reshape:\", x.shape)\n",
        "print(x)\n",
        "print(\"- - - - - \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eAyzHNF-GeYA",
        "outputId": "9c2b4213-d2d0-4a6d-addc-a39c51b3f212"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x: (3, 2)\n",
            "[[0. 1.]\n",
            " [2. 3.]\n",
            " [4. 5.]]\n",
            "- - - - - \n",
            "Shape of x after reshape: (2, 3)\n",
            "[[0. 1. 2.]\n",
            " [3. 4. 5.]]\n",
            "- - - - - \n",
            "Shape of x after reshape: (6, 1)\n",
            "[[0.]\n",
            " [1.]\n",
            " [2.]\n",
            " [3.]\n",
            " [4.]\n",
            " [5.]]\n",
            "- - - - - \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Geometric interpretation of tensor operations\n",
        "\n",
        "This section provides an intuitive graphical interpretation of tensor operations, which essentially apply a geometric transformation to the input tensor.\n",
        "\n",
        "Deep neural networks consist entirely of chains of tensor operations that are just simple geometric transformations of the input data, it follows that they can be interpreted as a very complex geometric transformation in a high-dimensional space, implemented via a series of simpler steps."
      ],
      "metadata": {
        "id": "jb9GbTcPLcrx"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vGGGXgHtLb_m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}