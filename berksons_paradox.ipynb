{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOmTqxnQWB10YYqDfTqsUaZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnantonn/personal-projects/blob/main/berksons_paradox.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Berkson's Paradox in Machine Learning\n",
        "\n",
        "Berkson's paradox, also known as Berkson's bias, collider bias, or Berkson's fallacy, is a result in conditional probability and statistics which is often found to be counterintuitive, and hence a veridical paradox. It is a complicating factor arising in statistical tests of proportions. Specifically, it arises when there is an ascertainment bias inherent in a study design. The effect is related to the explaining away phenomenon in Bayesian networks, and conditioning on a collider in graphical models.\n",
        "\n",
        "Reference: https://en.wikipedia.org/wiki/Berkson%27s_paradox"
      ],
      "metadata": {
        "id": "Biwt5vKGIerE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "#Get some observations for random variables X and Y\n",
        "def sample_X_Y(nb_exp):\n",
        "    X = []\n",
        "    Y = []\n",
        "    for i in range(nb_exp):\n",
        "        dice1 = random.randint(1,6)\n",
        "        dice2 = random.randint(1,6)\n",
        "        X.append(dice1 == 6)\n",
        "        Y.append(dice2 in [1,2])\n",
        "    return X, Y\n",
        "\n",
        "nb_exp=1_000_000\n",
        "X, Y = sample_X_Y(nb_exp)\n",
        "\n",
        "# compute P(X=1) and P(X1=1|Y=1) to check if X and Y are independent\n",
        "p_X = sum(X)/nb_exp\n",
        "p_X_Y = sum([X[i] for i in range(nb_exp) if Y[i]])/sum(Y)\n",
        "\n",
        "print(\"P(X=1) = \", round(p_X,5))\n",
        "print(\"P(X=1|Y=1) = \", round(p_X_Y,5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JTU7HTzkIh3B",
        "outputId": "b1e03f69-ea6b-419a-fb78-d8a572a3d02e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(X=1) =  0.16648\n",
            "P(X=1|Y=1) =  0.16642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# keep only the observations where X=1, Y=1 or both (remove when X=0 and Y=0)\n",
        "XZ = []\n",
        "YZ = []\n",
        "for i in range(nb_exp):\n",
        "    if X[i] or Y[i]:\n",
        "        XZ.append(X[i])\n",
        "        YZ.append(Y[i])\n",
        "nb_obs_Z = len(XZ)\n",
        "\n",
        "# compute P(X=1|Z=1) and P(X1=1|Y=1,Z=1) to check if X|Z and Y|Z are independent\n",
        "p_X_Z = sum(XZ)/nb_obs_Z\n",
        "p_X_Y_Z = sum([XZ[i] for i in range(nb_obs_Z) if YZ[i]])/sum(YZ)\n",
        "\n",
        "print(\"P(X=1|Z=1) = \", round(p_X_Z,5))\n",
        "print(\"P(X=1|Y=1,Z=1) = \", round(p_X_Y_Z,5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqNiriDdIooE",
        "outputId": "43269f0c-8307-44d1-8fa1-995eb9a8b279"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "P(X=1|Z=1) =  0.37468\n",
            "P(X=1|Y=1,Z=1) =  0.16642\n"
          ]
        }
      ]
    }
  ]
}